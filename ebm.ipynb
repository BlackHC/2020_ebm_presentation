{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Energy-based Models\n",
    "## Andreas Kirsch, Oct 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Energy\n",
    "\n",
    "We assign an energy to $E(x)$ every state $x$ of a model:\n",
    "\n",
    "$$E(x): \\mathcal{X} \\rightarrow \\mathbb{R}$$\n",
    "\n",
    "The intuition is that like in physics, our model describes a dynamic system in which states of low energy are preferred. Specifically, local minima form stable attractors. \n",
    "\n",
    "We describe our tasks in a way that low energies encode preferred states. \n",
    "\n",
    "The energy function has no \"zero\" point. It is a relative quantity, just like in physics: we only care about the difference in energy between different states.\n",
    "\n",
    "<img src=\"images/energy_function.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Usage\n",
    "#### Classification/Prediction\n",
    "The state can be (input, output):  $E(x,y): \\mathcal{X} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}.$\n",
    "Then we are interested in:\n",
    "$\\arg\\min_y E(x,y)$ for a given $x$.\n",
    "#### Error correction\n",
    "$x^* =  \\arg\\min E(x)$ s.t. $x \\in B_\\epsilon(x_0)$\n",
    "#### Completion\n",
    "For $x = (x_1,x_2)$, we want $x^* = \\arg\\min_x E(x_1, x_2)$ where $x_1$ is fixed and $x_2$ is unknown and sampled randomly.\n",
    "#### Content-addressable memory (CAM)\n",
    "All of these tasks (above) can be viewed as implementing content-addressable memory, which is about retrieving memory based on its (partial) content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ranking\n",
    "$E(x_1) > E(x_2)$?\n",
    "#### Out-of-distribution detection\n",
    "Decision problem: $E(x) > \\tau \\Rightarrow \\text{ood}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to turn $E(x)$ into a Probabilistic Model\n",
    "We can use the Gibbs distribution for that:\n",
    "\n",
    "$$p(x) = \\frac{\\exp(-E(x))}{\\int \\exp(-E(x)) \\,dx}$$\n",
    "\n",
    "Sometimes: $p(x) = \\frac{\\exp(-\\beta E(x))}{\\int \\exp(-\\beta E(x)) \\,dx}$ where $\\beta$ is the \"inverse temperature\" and only interesting for calibration purposes\n",
    "\n",
    "We also define the partition function(al):\n",
    "$$ Z_E := \\int \\exp(-E(x)) \\,dx $$\n",
    "then:\n",
    "$$ p(x) = \\frac{\\exp(-E(x))}{Z_E} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T07:17:39.626415Z",
     "start_time": "2020-10-30T07:17:39.617127Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\exp(-E(x))$ ensures positivity of the density. Moreover, it is the natural option given that we only care about relative energies. There ought to be no difference if we shift energies by a constant amount:\n",
    "\n",
    "$$p(x) = \\frac{\\exp(-E(x) - C)}{\\int \\exp(-E(x) - C) \\,dx} = \\frac{\\exp(-C) \\exp(-E(x))}{\\exp(-C) \\int \\exp(-E(x)) \\,dx} = \\frac{\\exp(-E(x))}{\\int \\exp(-E(x)) \\,dx} $$\n",
    "\n",
    "This property and the Gibbs measure might look familiar: the `softmin` function is a categorical version of it (`softmin(x) = softmax(-x))`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we train EBMs conceptually?\n",
    "\n",
    "The optimization problem is determined by the family of energy functions $\\mathcal{E}$ that is available and by a loss functional $\\mathcal{L}$ and the training data $D_{train} = \\{x_i\\}_i$.\n",
    "$$E^* = \\arg\\min_{E \\in \\mathcal{E}} \\mathcal{L}(E, D_{train})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The loss function $\\mathcal L$ can take many different forms: cross-entropy training is just one possible loss function.\n",
    "\n",
    "We want to push down energies for samples in the training set and pull up energies for other states with low energy.\n",
    "\n",
    "![Conceptual EBM training](images/EBM_training.png)\n",
    "(from \"A Tutorial on Energy-Based Learning\" by LeCun, 2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-entropy loss, one more time \n",
    "With $ p(x) = \\frac{\\exp(-E(x))}{Z_E} $:\n",
    "\n",
    "$$ \\mathcal{L}(E, D_{train}) = \\mathbb{E}_{\\hat{p}(x)} \\left [ -\\log p(x) \\right ] = \\mathbb{E}_{\\hat{p}(x)} \\left [ E(x) + \\log Z_E \\right ] $$ with the empirical distribution $$\\hat{p}(x) \\propto \\sum_{x' \\in D_{train}} \\delta_{x'}(x)$$\n",
    "\n",
    "### Derivative\n",
    "\n",
    "$$ d \\mathcal{L}(E, D_{train}) = \\mathbb{E}_{\\hat{p}(x)} \\left [ dE(x)  + \\frac{1}{Z_E} \\int \\exp(-E(x')) (-dE(x')) \\, dx' \\right ] = \\underbrace{\\mathbb{E}_{\\hat{p}(x)} dE(x)}_\\text{Positive samples} - \\underbrace{\\mathbb{E}_{p(x')} dE(x')}_\\text{Negative samples} $$\n",
    "\n",
    "(If $E$ is parameterized by $\\theta$, we can substitute $dE = \\frac{\\partial E}{\\partial \\theta} d\\theta$.)\n",
    "\n",
    "We push down the energy for positive samples and pull up the energy for negative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T09:02:50.436693Z",
     "start_time": "2020-10-30T09:02:50.424075Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How do we train it?\n",
    "\n",
    "$$ d \\mathcal{L}(E, D_{train}) = \\mathbb{E}_{\\hat{p}(x)} \\left [ dE(x)  + \\frac{1}{Z_E} \\int \\exp(-E(x')) (-dE(x')) \\, dx' \\right ] = \\underbrace{\\mathbb{E}_{\\hat{p}(x)} dE(x)}_\\text{Positive samples} - \\underbrace{\\mathbb{E}_{p(x')} dE(x')}_\\text{Negative samples} $$\n",
    "\n",
    "The \"positive samples\" term can be easily computed using the training set. \n",
    "\n",
    "**The \"negative samples\" term is the tricky part.**\n",
    "\n",
    "We can use different methods to sample from $p(x)$: MCMC, SGLD, HMC, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Contrastive Divergence\n",
    "\n",
    "Start MCMC from existing training samples and only run for a few steps\n",
    "\n",
    "Q: How does this compare to adversarial training? Add noise and follow the gradient for a few steps. \n",
    "Has anyone tried that actually?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"Your Classifier is secretely an EBM...\" by Grathwohl et al, 2019\n",
    "### Or how to turn $E(x, y)$ into a Probabilistic Model\n",
    "\n",
    "<img src=\"images/jem.png\" style=\"float: right;\"/>\n",
    "\n",
    "Let's say $y$ is categorical.\n",
    "\n",
    "$$ p(x,y) = \\frac{\\exp(-E(x, y))}{\\sum_y \\int \\exp(-E(x, y)) \\,dx} = \\frac{\\exp(-E(x, y))}{Z_E}$$\n",
    "\n",
    "### Marginal\n",
    "$$p(x) =  \\frac{\\sum_y \\exp(-E(x, y))}{\\sum_y \\int \\exp(-E(x, y)) \\,dx} $$\n",
    "$$ E(x) = - \\log \\sum_y \\exp(-E(x, y)) $$\n",
    "\n",
    "### Conditional\n",
    "$$ p(y | x) = \\frac{p(x,y)}{p(x)} = \\frac{\\exp(-E(x, y))}{\\sum_y \\exp(-E(x, y))} $$\n",
    "=> $p(y|x)$ is independent of $Z_E$! We can rewrite this into a well-known expression in DNNs:\n",
    "$$ p(y|x) = \\text{Softmax}( -E(x, \\cdot) ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Overall, we train $$ \\log p(x,y) = \\log p(x) + \\log p(y|x) $$ by training the marginal and conditional separately: the conditional $ \\log p(y|x) $ can be optimized using normal softmax-cross-entropy, whereas the marginal $\\log p(x)$ can be trained using SGLD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### After-thought\n",
    "\n",
    "When we train $p(x)$ for a given $x$, we don't want to change $p(y|x)$, do we? We only want to shift $p(x)$ by some $C = \\Delta p(x)$.\n",
    "\n",
    "$$ E(x) + C = - \\log( \\exp(-C)) - \\log \\sum_y \\exp(-E(x, y)) = -log \\left ( \\exp(-C) \\sum_y \\exp(-E(x, y)) \\right ) = -\\log \\sum_y \\exp(-(E(x,y) + C))$$\n",
    "\n",
    "However, does this happen in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hopfield networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T09:42:52.390431Z",
     "start_time": "2020-10-30T09:42:52.388137Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ising Model\n",
    "\n",
    "We want to model the magnetic spin of atoms in a lattice. The magnetic spins interact with each other to align themselves:\n",
    "\n",
    "* in the same direction, for ferromagnetic interactions, and\n",
    "* in opposing directions, for antiferromagnetic interactions.\n",
    "\n",
    "![Ferromagnetic material](images/Ising_ferromagnetic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Hamiltonian for the Ising Model is\n",
    "$$H(\\sigma)=-\\sum_{\\langle i j\\rangle} J_{i j} \\sigma_{i} \\sigma_{j}$$\n",
    "for discrete spin variables $\\sigma_i \\in \\{-1, +1\\}$ with interactions $J_{i,j}$.\n",
    "\n",
    "$J_{i,j} > 0$ for ferromagnetic interaction,\n",
    "$J_{i,j} < 0$ for antiferromagnetic interaction, and\n",
    "$J_{i,j} = 0$ for no interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Discrete) Hopfield networks \n",
    "\n",
    "*Hopfield networks are models for associative memory, so content-addressable memory.*\n",
    "\n",
    "We model a neuron's state as either ON or OFF, $S_i \\in \\{-1, +1\\}$.\n",
    "\n",
    "The follow the following update rule:\n",
    "\n",
    "$$S_{i} \\leftarrow\\left\\{\\begin{array}{ll}+1 & \\text { if } \\sum_{j} w_{i j} S_{j} \\geq \\theta_{i} \\\\ -1 & \\text { otherwise }\\end{array}\\right.$$\n",
    "\n",
    "where $w_{i j}$ specifies the weights of the synaptic connection from neuron $j$ to $i$, and $\\theta_i$ is the activation threshold for neuron $i$.\n",
    "\n",
    "This leads to the following energy function:\n",
    "\n",
    "$$E=-\\frac{1}{2} \\sum_{i, j} w_{i j} S_{i} S_{j}+\\sum_{i} \\theta_{i} s_{i}$$\n",
    "\n",
    "We set $\\theta_i = 0$ here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hebbian learning\n",
    "\n",
    "To learn patterns $\\mu = {p^\\mu_i} \\ in M$, we set (for $i \\not = j$):\n",
    "$$w_{i j} = \\frac{1}{| M |} \\sum_{\\mu \\in M} p^\\mu_i p^\\mu_j$$\n",
    "and $w_{i i} = 0$. \n",
    "\n",
    "![Learnt energy function](images/hopfield_attractor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In practice\n",
    "\n",
    "We can either start from a randomly pattern and let it converge to a stored pattern (as a generative model), or we can partially corrupt data and have the model inpaint the rest.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/hopfield_example.png\" width=\"45%\" style=\"display:inline-block;\" /><img src=\"images/hopfield_weights.png\" width=\"45%\" style=\"display:inline-block;\"/>\n",
    "</div>\n",
    "\n",
    "(from https://github.com/takyamamoto/Hopfield-Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T10:23:49.869220Z",
     "start_time": "2020-10-30T10:23:49.865945Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sources\n",
    "\n",
    "#### Energy-based models\n",
    "\n",
    "* LeCun, Y. et al. “A Tutorial on Energy-Based Learning.” (2006)\n",
    "* Grathwohl, Will, et al. \"Your classifier is secretly an energy based model and you should treat it like one.\" International Conference on Learning Representations. 2019.\n",
    "\n",
    "\n",
    "\n",
    "#### Hopfield networks\n",
    "\n",
    "* Ch. 17, \"Neuronal Dynamics: From single neurons to networks and models of cognition\", https://neuronaldynamics.epfl.ch/online/Ch17.S2.html\n",
    "* https://neuronaldynamics-exercises.readthedocs.io/en/latest/exercises/hopfield-network.html\n",
    "* https://github.com/takyamamoto/Hopfield-Network"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
